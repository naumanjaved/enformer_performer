{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0f91784-f159-4d80-a394-1c57ea7d900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "#os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import metrics as metrics\n",
    "from optimizers import *\n",
    "import schedulers as schedulers\n",
    "\n",
    "import training_utils as training_utils\n",
    "\n",
    "import enformer_performer as enformer_performer\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d33684ed-393f-4af6-83b8-ed8150d9be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system node-2 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system node-2 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-2')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy=\\\n",
    "        tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    options.experimental_threading.max_intra_op_parallelism=1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1 # batch size 24, use LR ~ 2.5 e -04\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93effd89-8681-48e6-be68-36e027605040",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterators={'human': ('gs://genformer_data/expanded_originals/196k',5313),\n",
    "           'mouse': ('gs://genformer_data/expanded_originals/196k',1643)}\n",
    "g = tf.random.Generator.from_non_deterministic_state()\n",
    "tr_data_it_dict,val_data_it_dict,val_data_TSS_it =  \\\n",
    "    training_utils.return_distributed_iterators(iterators,\n",
    "                                                \"gs://genformer_data/expanded_originals/196k/human/tfrecords_tss\",\n",
    "                                                5313,\n",
    "                                                 GLOBAL_BATCH_SIZE,\n",
    "                                                 196608,\n",
    "                                                 1536,\n",
    "                                                 320,\n",
    "                                                 10,\n",
    "                                                 4,\n",
    "                                                 10,\n",
    "                                                 strategy,\n",
    "                                                 options,\n",
    "                                                 g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0de2869-14d8-46c8-9efd-77cb51e28a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    inits=training_utils.get_initializers(\"gs://picard-testing-176520/sonnet_weights/sonnet_weights\")\n",
    "    model = enformer_performer.enformer_performer(\n",
    "        num_transformer_layers=6,\n",
    "        num_heads=8,\n",
    "        heads_channels= {'human': 5313},\n",
    "        out_length=1536,\n",
    "        target_length=896,\n",
    "        stable_variant=True,\n",
    "        dim=192,\n",
    "        d_model=1536,\n",
    "        norm=True,\n",
    "        max_seq_length=1536,\n",
    "        nb_random_features=256,\n",
    "        hidden_size=1536,\n",
    "        numerical_stabilizer=0.001,\n",
    "        rel_pos_bins=1536,\n",
    "        use_mask_pos=False,\n",
    "        use_rot_emb=True,\n",
    "        load_init=True,\n",
    "        inits=inits,\n",
    "        freeze_conv_layers=True,\n",
    "        kernel_transformation=\"softmax_kernel_transformation\",\n",
    "        normalize=True,\n",
    "        seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb20d1ad-4e38-4e69-9e29-75a19e7bfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():        \n",
    "\n",
    "    optimizer1 = tf.keras.optimizers.Adam(learning_rate=1.0e-04)\n",
    "\n",
    "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=1.0e-04)\n",
    "    optimizers_in = optimizer1,optimizer2\n",
    "\n",
    "    metric_dict = {}\n",
    "    organism_dict = {'human': 50}\n",
    "\n",
    "                               \n",
    "    dist_train_step, dist_val_step_h,dist_val_step_m, val_step_TSS, build_step,metric_dict = training_utils.return_train_val_functions(model,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       organism_dict,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       optimizers_in,\n",
    "                                                                                                                                        4675,\n",
    "                                                                                                                                         strategy,\n",
    "                                                                                                                                         metric_dict, \n",
    "                                                                                                                                         GLOBAL_BATCH_SIZE,\n",
    "                                                                                                                                        5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2400a655-9fec-4661-aa56-415bf14c3191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch_ 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():        \n",
    "    ### main training loop\n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, 4):\n",
    "        print('starting epoch_', str(epoch_i))\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            # run once to build the model w/o updating anything\n",
    "            build_step(val_data_it_dict['human'])\n",
    "        break\n",
    "        assert len(organism_dict.keys()) == len(tr_data_it_dict.keys())\n",
    "            \n",
    "        iters = (tr_data_it_dict['human'],\n",
    "                        tr_data_it_dict['mouse'])\n",
    "        dist_train_step(iters)\n",
    "        \n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('hg_train_loss: ' + str(metric_dict['human_tr'].result().numpy()))\n",
    "        \n",
    "        print('training duration(mins): ' + str(duration))\n",
    "\n",
    "        start = time.time()\n",
    "        dist_val_step_h(val_data_it_dict['human'])\n",
    "\n",
    "        print('val_loss: ' + str(metric_dict['human_val'].result().numpy()))\n",
    "        val_losses.append(metric_dict['human_val'].result().numpy())\n",
    "\n",
    "        print('human_pearsonsR: ')\n",
    "        pearsonsR=metric_dict['human_pearsonsR'].result()['PearsonR'].numpy()\n",
    "        print(pearsonsR)\n",
    "\n",
    "        val_pearsons.append(np.nanmedian(pearsonsR))\n",
    "        print('human_R2: ')\n",
    "        print(metric_dict['human_R2'].result()['R2'].numpy())\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i) + ' validation')\n",
    "        print('validation duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "\n",
    "        \n",
    "        val_step_TSS(val_data_TSS_it)\n",
    "        \n",
    "\n",
    "        y_trues = metric_dict['hg_corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['hg_corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['hg_corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['hg_corr_stats'].result()['gene_map'].numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (epoch_i > 2):\n",
    "            stop_criteria,patience_counter,best_epoch = \\\n",
    "                training_utils.early_stopping(current_val_loss=val_losses[-1],\n",
    "                                                logged_val_losses=val_losses,\n",
    "                                                current_pearsons=val_pearsons[-1],\n",
    "                                                logged_pearsons=val_pearsons,\n",
    "                                                current_epoch=epoch_i,\n",
    "                                                best_epoch=best_epoch,\n",
    "                                                save_freq=5,\n",
    "                                                patience=5,\n",
    "                                                patience_counter=patience_counter,\n",
    "                                                min_delta=1.0e-05,\n",
    "                                                model=enformer_model,\n",
    "                                                save_directory=\"gs://picard-testing-176520/test\",\n",
    "                                                saved_model_basename=\"test_model\",\n",
    "                                                checkpoint=checkpoint)\n",
    "        #plt.close('all')\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42951181-23d2-481e-a8f5-ea94b19ab32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=\"gs://picard-testing-176520/sonnet_weights/sonnet_weights\"\n",
    "inside_checkpoint=tf.train.list_variables(tf.train.latest_checkpoint(checkpoint_path))\n",
    "reader = tf.train.load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac2f9e4c-4b18-4336-ab10-3aba6e215371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_1:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_2:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_3:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_4:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_5:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_6:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/gamma/replica_7:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([1.3839775, 1.6160904, 1.7670952, ..., 2.1606104, 1.6481336,\n",
       "        1.745201 ], dtype=float32)>\n",
       " },\n",
       " TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_1:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_2:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_3:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_4:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_5:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_6:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/beta/replica_7:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([-0.5005564 , -0.33965045, -1.3100986 , ..., -0.42265135,\n",
       "        -1.2490441 , -0.68814456], dtype=float32)>\n",
       " },\n",
       " TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_1:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_2:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_3:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_4:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_5:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_6:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_mean/replica_7:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 , -3.0467067,\n",
       "        -9.030095 ], dtype=float32)>\n",
       " },\n",
       " TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_1:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_2:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_3:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_4:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_5:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_6:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_26/moving_variance/replica_7:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([313.23334, 138.29478, 487.9567 , ..., 915.9154 , 142.35913,\n",
       "        344.57874], dtype=float32)>\n",
       " },\n",
       " <AutoCastDistributedVariable dtype=float32 dtype_to_cast_to=float32 inner_variable=TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'conv1d_28/kernel:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   1: <tf.Variable 'conv1d_28/kernel/replica_1:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   2: <tf.Variable 'conv1d_28/kernel/replica_2:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   3: <tf.Variable 'conv1d_28/kernel/replica_3:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   4: <tf.Variable 'conv1d_28/kernel/replica_4:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   5: <tf.Variable 'conv1d_28/kernel/replica_5:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   6: <tf.Variable 'conv1d_28/kernel/replica_6:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>,\n",
       "   7: <tf.Variable 'conv1d_28/kernel/replica_7:0' shape=(1, 1536, 1536) dtype=float32, numpy=\n",
       " array([[[ 0.54621756,  0.22558236, -0.18999055, ...,  0.0103948 ,\n",
       "          -0.28519106,  0.03258709],\n",
       "         [ 0.20211442, -1.5442028 ,  0.21267551, ..., -0.331139  ,\n",
       "           0.41316542, -0.28549486],\n",
       "         [ 0.29285485,  0.24852186,  2.9850855 , ...,  0.09966182,\n",
       "          -0.23844801,  0.05349489],\n",
       "         ...,\n",
       "         [ 0.3068441 , -0.06627747, -0.16345118, ...,  1.5888743 ,\n",
       "          -0.10253942,  0.23532961],\n",
       "         [ 0.23160578,  0.37523258, -0.49248004, ..., -0.13982973,\n",
       "           0.7402752 , -0.25623438],\n",
       "         [ 0.08794025, -0.07529943,  0.13228907, ..., -0.49420333,\n",
       "          -0.39772043,  1.9063728 ]]], dtype=float32)>\n",
       " }>,\n",
       " <AutoCastDistributedVariable dtype=float32 dtype_to_cast_to=float32 inner_variable=TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'conv1d_28/bias:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   1: <tf.Variable 'conv1d_28/bias/replica_1:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   2: <tf.Variable 'conv1d_28/bias/replica_2:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   3: <tf.Variable 'conv1d_28/bias/replica_3:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   4: <tf.Variable 'conv1d_28/bias/replica_4:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   5: <tf.Variable 'conv1d_28/bias/replica_5:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   6: <tf.Variable 'conv1d_28/bias/replica_6:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>,\n",
       "   7: <tf.Variable 'conv1d_28/bias/replica_7:0' shape=(1536,) dtype=float32, numpy=\n",
       " array([ 0.3806832 , -0.03304794, -0.0026828 , ..., -0.00504916,\n",
       "        -0.04627301, -0.00290691], dtype=float32)>\n",
       " }>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].layers[5].layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "884e9db6-6dd2-4ec6-b71a-c80491fa29af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[87.602135 , -7.780264 ,  2.9318128, ...,  4.761898 ,\n",
       "         -3.0467067, -9.030095 ]]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.get_tensor('module/_trunk/_layers/1/_layers/5/_layers/1/_module/_layers/0/moving_mean/average/.ATTRIBUTES/VARIABLE_VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7115bb-73bd-4146-af2d-1b2ebbdda3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deserialize_val_TSS(serialized_example,\n",
    "                        input_length, output_length,crop_size,\n",
    "                        max_shift,num_targets):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.string),\n",
    "        'tss_mask': tf.io.FixedLenFeature([], tf.string),\n",
    "        'gene_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bin_unique': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    shift = 5\n",
    "    input_seq_length = input_length + max_shift\n",
    "    interval_end = input_length + shift\n",
    "    \n",
    "\n",
    "    example = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "    sequence = tf.reshape(sequence, (input_length + max_shift, 4))\n",
    "    sequence = tf.cast(sequence, tf.float32)\n",
    "    sequence = tf.slice(sequence, [shift,0],[input_length,-1])\n",
    "    \n",
    "    target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "    target = tf.reshape(target,\n",
    "                        (output_length, num_targets))\n",
    "    #print(target.shape)\n",
    "    target = tf.slice(target,[crop_size,0],\n",
    "                             [output_length - 2*crop_size,-1])\n",
    "\n",
    "    bin_unique = tf.io.parse_tensor(example['bin_unique'],\n",
    "                                  out_type=tf.int32)\n",
    "    \n",
    "    tss_mask = tf.io.parse_tensor(example['tss_mask'],\n",
    "                                  out_type=tf.int32)\n",
    "    tss_mask = tf.slice(tss_mask,[crop_size,0],\n",
    "                             [output_length - 2*crop_size,-1])\n",
    "\n",
    "    gene_name= tf.io.parse_tensor(example['gene_name'],out_type=tf.int32)\n",
    "    gene_name = tf.tile(tf.expand_dims(gene_name,axis=0),[638])\n",
    "    cell_types = tf.range(0,638)\n",
    "    \n",
    "\n",
    "    return {'sequence': tf.ensure_shape(sequence,\n",
    "                                        [input_length,4]),\n",
    "            'target': tf.ensure_shape(target,\n",
    "                                      [output_length - 2*crop_size,num_targets]),\n",
    "            'tss_mask': tf.ensure_shape(tss_mask,\n",
    "                                        [output_length - 2*crop_size,1]),\n",
    "            'gene_name': tf.ensure_shape(gene_name,\n",
    "                                         [638,]),\n",
    "            'bin_unique': bin_unique,\n",
    "            'cell_types': tf.ensure_shape(cell_types,\n",
    "                                           [638,])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f01928-3667-4096-a422-57cb5c0bfd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:01:59.924312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 15:01:59.924397: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 15:01:59.924422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 15:01:59.924831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(\"gs://genformer_data/expanded_originals_tss_mask_no_TF/393k/human/tfrecords/train-0-100.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "#dataset = dataset.with_options(options)\n",
    "\n",
    "dataset = dataset.map(lambda record: deserialize_val_TSS(record,\n",
    "                                                         393216, \n",
    "                                                        896,\n",
    "                                                        0,\n",
    "                                                         10,\n",
    "                                                         3387),\n",
    "                      deterministic=False,\n",
    "                      num_parallel_calls=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70f07a6f-c9ac-4031-9dc7-1e52b6992a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73700ea9-c4a8-4009-bd5b-7dbb1dfa7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.ones(10,dtype=tf.float32)\n",
    "tf.reshape(test, [-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da96de4d-50fc-44a1-ae21-8c2e743eed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.nn.experimental.stateless_dropout(test, \n",
    "                                     rate=0.20, \n",
    "                                     seed=[0,4]) / (1. / (1.0-0.20))\n",
    "test = tf.expand_dims(test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5df4708a-7f42-4b60-883c-13d6a3cee41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.tile(test, [1,5]),[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe33934-55d0-4590-aa74-82eeb4647bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(sequence):\n",
    "    '''\n",
    "    convert input string tensor to one hot encoded\n",
    "    will replace all N character with 0 0 0 0\n",
    "    '''\n",
    "    vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "    mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "    init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                               values=mapping)\n",
    "    table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "    input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "    out = tf.one_hot(table.lookup(input_characters), \n",
    "                      depth = 4, \n",
    "                      dtype=tf.float32)\n",
    "    return out\n",
    "\n",
    "def deserialize_val_TSS(serialized_example,input_length,max_shift,output_length_ATAC,\n",
    "                        output_length,crop_size,output_res,predict_masked_atac_bool,atac_mask_dropout, use_global_acc, use_atac, log_atac,g):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cage': tf.io.FixedLenFeature([], tf.string),\n",
    "        'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cell_specific_conv_arr': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    seq_shift = 5\n",
    "    input_seq_length = input_length + max_shift\n",
    "\n",
    "    ### rev_comp\n",
    "    #rev_comp = random.randrange(0,2)\n",
    "\n",
    "    data = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                 seq_shift,input_length))\n",
    "    \n",
    "    \n",
    "    #### parse ATAC and transform as specified\n",
    "    atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length_ATAC,1])\n",
    "    diff = tf.math.sqrt(tf.nn.relu(atac - 64.0 * tf.ones(atac.shape)))\n",
    "    atac = tf.clip_by_value(atac, clip_value_min=0.0, clip_value_max=64.0) + diff\n",
    "    atac = tf.cast(tf.cast(atac,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "    atac_target = atac\n",
    "\n",
    "    if log_atac: \n",
    "        atac = tf.math.log1p(atac)\n",
    "        \n",
    "        \n",
    "    if not use_atac:\n",
    "        atac = tf.math.abs(g.normal(atac.shape,\n",
    "                             mean=0.0,\n",
    "                             stddev=0.00001,\n",
    "                             dtype=tf.float32))\n",
    "                           \n",
    "    ### here we generate a masked output vector length since we are predicting at 1536\n",
    "    atac_mask = tf.ones(output_length // 2,dtype=tf.float32)\n",
    "    atac_mask=tf.nn.experimental.stateless_dropout(atac_mask, \n",
    "                                                     rate=(atac_mask_dropout), \n",
    "                                                     seed=[0,seq_shift]) / (1. / (1.0-(atac_mask_dropout)))\n",
    "    atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "    atac_mask = tf.tile(atac_mask, [1,2])\n",
    "    atac_mask = tf.reshape(atac_mask, [-1])\n",
    "    atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "    if atac_mask_dropout == 0.0:\n",
    "        atac_mask_store = tf.ones_like(atac_mask)\n",
    "    else:\n",
    "        atac_mask_store = 1.0 - atac_mask ## invert the mask, since we want to store which values were masked and loss should be computed over\n",
    "    atac_mask_store = tf.slice(atac_mask_store,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "    tiling_req = output_length_ATAC // output_length\n",
    "    atac_mask = tf.expand_dims(tf.reshape(tf.tile(atac_mask, [1,tiling_req]),[-1]),axis=1)\n",
    "\n",
    "    masked_atac = atac * atac_mask\n",
    "    \n",
    "    cage = tf.ensure_shape(tf.io.parse_tensor(data['cage'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length - 2*crop_size,1])\n",
    "    diff = tf.math.sqrt(tf.nn.relu(cage - 850.0 * tf.ones(cage.shape)))\n",
    "    cage = tf.clip_by_value(cage, clip_value_min=0.0, clip_value_max=850.0) + diff\n",
    "    cage = tf.cast(tf.cast(cage,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "    \n",
    "    tss_tokens = tf.io.parse_tensor(data['tss_tokens'],\n",
    "                                  out_type=tf.int32)\n",
    "    tss_tokens = tf.expand_dims(tss_tokens,axis=1)\n",
    "    \n",
    "    global_acc = tf.ensure_shape(tf.io.parse_tensor(data['cell_specific_conv_arr'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [1536])\n",
    "    global_acc=tf.expand_dims(global_acc,axis=0)\n",
    "    global_acc = tf.math.asinh(global_acc)\n",
    "    global_acc = (global_acc - tf.math.reduce_mean(global_acc)) / tf.math.reduce_std(global_acc)\n",
    "    \n",
    "    if not use_global_acc:\n",
    "        global_acc = g.normal(global_acc.shape,\n",
    "                              mean=0.0,\n",
    "                              stddev=0.00025,\n",
    "                              dtype=tf.float32)\n",
    "\n",
    "    if predict_masked_atac_bool:\n",
    "        atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,tiling_req]),axis=1,keepdims=True)\n",
    "        diff = tf.math.sqrt(tf.nn.relu(atac_out - 64.0 * tf.ones(atac_out.shape)))\n",
    "        atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=64.0) + diff\n",
    "        atac_out = tf.cast(tf.cast(atac_out,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "        atac_out = tf.slice(atac_out,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "        target = tf.concat([atac_out,cage],axis=1)\n",
    "    \n",
    "\n",
    "    print(tss_tokens.shape)\n",
    "    \n",
    "    if predict_masked_atac_bool:\n",
    "        return {'sequence': tf.ensure_shape(sequence,\n",
    "                                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(masked_atac,\n",
    "                                          [output_length_ATAC,1]),\n",
    "                'atac_mask': tf.ensure_shape(atac_mask_store,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'target': tf.ensure_shape(target,\n",
    "                                          [output_length-crop_size*2,2]),\n",
    "                'tss_tokens': tf.ensure_shape(tss_tokens,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'global_acc': tf.ensure_shape(global_acc,\n",
    "                                          [1,1536])}\n",
    "    else:\n",
    "        return {'sequence': tf.ensure_shape(sequence,\n",
    "                                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(atac,\n",
    "                                          [output_length_ATAC,1]),\n",
    "                'target': tf.ensure_shape(cage,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'tss_tokens': tf.ensure_shape(tss_tokens,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'global_acc': tf.ensure_shape(global_acc,\n",
    "                                          [1,1536])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "006b94df-2730-4477-b685-c5dd2fca60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(\"gs://picard-testing-176520/test/train/HG_A375.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "g = tf.random.Generator.from_non_deterministic_state()\n",
    "dataset = dataset.map(lambda record: deserialize_val_TSS(record,\n",
    "                                                         65536,\n",
    "                                                         10,\n",
    "                                                         16384,\n",
    "                                                         512,\n",
    "                                                         100,\n",
    "                                                         128,\n",
    "                                                         True,\n",
    "                                                         0.0, \n",
    "                                                         True, \n",
    "                                                         True, \n",
    "                                                         True,\n",
    "                                                         g),\n",
    "                      deterministic=False,\n",
    "                      num_parallel_calls=4)\n",
    "test = iter(dataset)\n",
    "out = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8421684c-c02c-4285-9326-7d8ed8ff648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(312,), dtype=int32, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = next(test)\n",
    "out['tss_tokens'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c24cac45-b709-473d-bb0b-b40efce9fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(65536, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['sequence'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64b4981f-353e-4a24-bccc-7934bd7dd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask=tf.concat([tf.ones([100,1],dtype=tf.int32), (1-out['tss_tokens']),tf.ones([100,1],dtype=tf.int32)],axis=0)\n",
    "\n",
    "out_mask = tf.reshape(tf.tile(out_mask, [1,128]), [65536,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "276b6f31-92cd-4ead-b928-b97c02e2ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out=out['sequence'] * tf.cast(out_mask,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa0a5068-2bde-48df-aeb1-11bd34f7f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_compress = tf.reduce_sum(test_out, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da86cabb-aaf8-4174-a7f4-4a6e4b41d012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out[32768:32788,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1eed95d5-c553-4414-a6a2-b6d7a382d845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['sequence'][39768:39788,:] == test_out[39768:39788,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a3157-b865-46f1-bd7b-e4116946e4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
