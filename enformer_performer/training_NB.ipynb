{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f91784-f159-4d80-a394-1c57ea7d900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:15:51.130436: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 16:15:51.291319: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-10 16:15:51.291349: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-10 16:15:52.167023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-10 16:15:52.167149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-10 16:15:52.167163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "#os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import metrics as metrics\n",
    "from optimizers import *\n",
    "import schedulers as schedulers\n",
    "\n",
    "import training_utils as training_utils\n",
    "\n",
    "import enformer_performer as enformer_performer\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33684ed-393f-4af6-83b8-ed8150d9be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:15:53.506159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-10 16:15:53.506212: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-10 16:15:53.506245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:15:53.780159: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 16:15:53.803118: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://localhost:57833\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-2')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy=\\\n",
    "        tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    options.experimental_threading.max_intra_op_parallelism=1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1 # batch size 24, use LR ~ 2.5 e -04\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93effd89-8681-48e6-be68-36e027605040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "iterators={'human': ('gs://genformer_data/expanded_originals/196k',5313),\n",
    "           'mouse': ('gs://genformer_data/expanded_originals/196k',1643)}\n",
    "g = tf.random.Generator.from_non_deterministic_state()\n",
    "tr_data_it_dict,val_data_it_dict,val_data_TSS_it =  \\\n",
    "    training_utils.return_distributed_iterators(iterators,\n",
    "                                                \"gs://genformer_data/expanded_originals/196k/human/tfrecords_tss\",\n",
    "                                                5313,\n",
    "                                                 GLOBAL_BATCH_SIZE,\n",
    "                                                 196608,\n",
    "                                                 1536,\n",
    "                                                 320,\n",
    "                                                 10,\n",
    "                                                 4,\n",
    "                                                 10,\n",
    "                                                 strategy,\n",
    "                                                 options,\n",
    "                                                 g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0de2869-14d8-46c8-9efd-77cb51e28a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    inits=training_utils.get_initializers(\"gs://picard-testing-176520/sonnet_weights/sonnet_weights\")\n",
    "    model = enformer_performer.enformer_performer(\n",
    "        num_transformer_layers=6,\n",
    "        num_heads=8,\n",
    "        heads_channels= {'human': 5313},\n",
    "        out_length=1536,\n",
    "        target_length=896,\n",
    "        stable_variant=True,\n",
    "        dim=192,\n",
    "        d_model=1536,\n",
    "        norm=True,\n",
    "        max_seq_length=1536,\n",
    "        nb_random_features=256,\n",
    "        hidden_size=1536,\n",
    "        numerical_stabilizer=0.001,\n",
    "        rel_pos_bins=1536,\n",
    "        use_mask_pos=False,\n",
    "        use_rot_emb=True,\n",
    "        load_init=True,\n",
    "        inits=inits,\n",
    "        kernel_transformation=\"softmax_kernel_transformation\",\n",
    "        normalize=True,\n",
    "        seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb20d1ad-4e38-4e69-9e29-75a19e7bfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():        \n",
    "\n",
    "    optimizer1 = tf.keras.optimizers.Adam(learning_rate=1.0e-04)\n",
    "\n",
    "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=1.0e-04)\n",
    "    optimizers_in = optimizer1,optimizer2\n",
    "\n",
    "    metric_dict = {}\n",
    "    organism_dict = {'human': 50}\n",
    "\n",
    "                               \n",
    "    dist_train_step, dist_val_step_h,dist_val_step_m, val_step_TSS, build_step,metric_dict = training_utils.return_train_val_functions(model,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       organism_dict,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       optimizers_in,\n",
    "                                                                                                                                        4675,\n",
    "                                                                                                                                         strategy,\n",
    "                                                                                                                                         metric_dict, \n",
    "                                                                                                                                         GLOBAL_BATCH_SIZE,\n",
    "                                                                                                                                        5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2400a655-9fec-4661-aa56-415bf14c3191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch_ 1\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():        \n",
    "    ### main training loop\n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, 4):\n",
    "        print('starting epoch_', str(epoch_i))\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            # run once to build the model w/o updating anything\n",
    "            build_step(val_data_it_dict['human'])\n",
    "        break\n",
    "        assert len(organism_dict.keys()) == len(tr_data_it_dict.keys())\n",
    "            \n",
    "        iters = (tr_data_it_dict['human'],\n",
    "                        tr_data_it_dict['mouse'])\n",
    "        dist_train_step(iters)\n",
    "        \n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('hg_train_loss: ' + str(metric_dict['human_tr'].result().numpy()))\n",
    "        \n",
    "        print('training duration(mins): ' + str(duration))\n",
    "\n",
    "        start = time.time()\n",
    "        dist_val_step_h(val_data_it_dict['human'])\n",
    "\n",
    "        print('val_loss: ' + str(metric_dict['human_val'].result().numpy()))\n",
    "        val_losses.append(metric_dict['human_val'].result().numpy())\n",
    "\n",
    "        print('human_pearsonsR: ')\n",
    "        pearsonsR=metric_dict['human_pearsonsR'].result()['PearsonR'].numpy()\n",
    "        print(pearsonsR)\n",
    "\n",
    "        val_pearsons.append(np.nanmedian(pearsonsR))\n",
    "        print('human_R2: ')\n",
    "        print(metric_dict['human_R2'].result()['R2'].numpy())\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i) + ' validation')\n",
    "        print('validation duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "\n",
    "        \n",
    "        val_step_TSS(val_data_TSS_it)\n",
    "        \n",
    "\n",
    "        y_trues = metric_dict['hg_corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['hg_corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['hg_corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['hg_corr_stats'].result()['gene_map'].numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (epoch_i > 2):\n",
    "            stop_criteria,patience_counter,best_epoch = \\\n",
    "                training_utils.early_stopping(current_val_loss=val_losses[-1],\n",
    "                                                logged_val_losses=val_losses,\n",
    "                                                current_pearsons=val_pearsons[-1],\n",
    "                                                logged_pearsons=val_pearsons,\n",
    "                                                current_epoch=epoch_i,\n",
    "                                                best_epoch=best_epoch,\n",
    "                                                save_freq=5,\n",
    "                                                patience=5,\n",
    "                                                patience_counter=patience_counter,\n",
    "                                                min_delta=1.0e-05,\n",
    "                                                model=enformer_model,\n",
    "                                                save_directory=\"gs://picard-testing-176520/test\",\n",
    "                                                saved_model_basename=\"test_model\",\n",
    "                                                checkpoint=checkpoint)\n",
    "        #plt.close('all')\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42951181-23d2-481e-a8f5-ea94b19ab32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=\"gs://picard-testing-176520/sonnet_weights/sonnet_weights\"\n",
    "inside_checkpoint=tf.train.list_variables(tf.train.latest_checkpoint(checkpoint_path))\n",
    "reader = tf.train.load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac2f9e4c-4b18-4336-ab10-3aba6e215371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_1:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_2:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_3:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_4:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_5:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_6:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/gamma/replica_7:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([1.1897506 , 1.1832818 , 1.0432662 , ..., 0.8558862 , 0.9469875 ,\n",
       "        0.97384024], dtype=float32)>\n",
       " },\n",
       " TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_1:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_2:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_3:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_4:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_5:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_6:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/beta/replica_7:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-0.54177374, -0.9214125 , -0.16616626, ...,  0.14483036,\n",
       "        -0.18115366, -0.28283435], dtype=float32)>\n",
       " },\n",
       " TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_1:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_2:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_3:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_4:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_5:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_6:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_mean/replica_7:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([-3.5949037,  2.9643297,  0.7306924, ...,  7.0711923, -1.3804306,\n",
       "        10.347774 ], dtype=float32)>\n",
       " },\n",
       " TPUDistributedVariable:{\n",
       "   0: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   1: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_1:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   2: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_2:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   3: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_3:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   4: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_4:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   5: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_5:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   6: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_6:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>,\n",
       "   7: <tf.Variable 'sync_batch_norm_fp32/sync_batch_normalization_25/moving_variance/replica_7:0' shape=(1280,) dtype=float32, numpy=\n",
       " array([ 206.68503,  267.2325 , 1922.8629 , ...,  162.02429,  183.13127,\n",
       "         232.3363 ], dtype=float32)>\n",
       " }]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].layers[5].layers[0].layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7115bb-73bd-4146-af2d-1b2ebbdda3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deserialize_val_TSS(serialized_example,\n",
    "                        input_length, output_length,crop_size,\n",
    "                        max_shift,num_targets):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.string),\n",
    "        'tss_mask': tf.io.FixedLenFeature([], tf.string),\n",
    "        'gene_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bin_unique': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    shift = 5\n",
    "    input_seq_length = input_length + max_shift\n",
    "    interval_end = input_length + shift\n",
    "    \n",
    "\n",
    "    example = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "    sequence = tf.reshape(sequence, (input_length + max_shift, 4))\n",
    "    sequence = tf.cast(sequence, tf.float32)\n",
    "    sequence = tf.slice(sequence, [shift,0],[input_length,-1])\n",
    "    \n",
    "    target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "    target = tf.reshape(target,\n",
    "                        (output_length, num_targets))\n",
    "    #print(target.shape)\n",
    "    target = tf.slice(target,[crop_size,0],\n",
    "                             [output_length - 2*crop_size,-1])\n",
    "\n",
    "    bin_unique = tf.io.parse_tensor(example['bin_unique'],\n",
    "                                  out_type=tf.int32)\n",
    "    \n",
    "    tss_mask = tf.io.parse_tensor(example['tss_mask'],\n",
    "                                  out_type=tf.int32)\n",
    "    tss_mask = tf.slice(tss_mask,[crop_size,0],\n",
    "                             [output_length - 2*crop_size,-1])\n",
    "\n",
    "    gene_name= tf.io.parse_tensor(example['gene_name'],out_type=tf.int32)\n",
    "    gene_name = tf.tile(tf.expand_dims(gene_name,axis=0),[638])\n",
    "    cell_types = tf.range(0,638)\n",
    "    \n",
    "\n",
    "    return {'sequence': tf.ensure_shape(sequence,\n",
    "                                        [input_length,4]),\n",
    "            'target': tf.ensure_shape(target,\n",
    "                                      [output_length - 2*crop_size,num_targets]),\n",
    "            'tss_mask': tf.ensure_shape(tss_mask,\n",
    "                                        [output_length - 2*crop_size,1]),\n",
    "            'gene_name': tf.ensure_shape(gene_name,\n",
    "                                         [638,]),\n",
    "            'bin_unique': bin_unique,\n",
    "            'cell_types': tf.ensure_shape(cell_types,\n",
    "                                           [638,])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f01928-3667-4096-a422-57cb5c0bfd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:01:59.924312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 15:01:59.924397: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 15:01:59.924422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 15:01:59.924831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(\"gs://genformer_data/expanded_originals_tss_mask_no_TF/393k/human/tfrecords/train-0-100.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "#dataset = dataset.with_options(options)\n",
    "\n",
    "dataset = dataset.map(lambda record: deserialize_val_TSS(record,\n",
    "                                                         393216, \n",
    "                                                        896,\n",
    "                                                        0,\n",
    "                                                         10,\n",
    "                                                         3387),\n",
    "                      deterministic=False,\n",
    "                      num_parallel_calls=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70f07a6f-c9ac-4031-9dc7-1e52b6992a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73700ea9-c4a8-4009-bd5b-7dbb1dfa7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.ones(10,dtype=tf.float32)\n",
    "tf.reshape(test, [-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da96de4d-50fc-44a1-ae21-8c2e743eed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.nn.experimental.stateless_dropout(test, \n",
    "                                     rate=0.20, \n",
    "                                     seed=[0,4]) / (1. / (1.0-0.20))\n",
    "test = tf.expand_dims(test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5df4708a-7f42-4b60-883c-13d6a3cee41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.tile(test, [1,5]),[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe33934-55d0-4590-aa74-82eeb4647bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(sequence):\n",
    "    '''\n",
    "    convert input string tensor to one hot encoded\n",
    "    will replace all N character with 0 0 0 0\n",
    "    '''\n",
    "    vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "    mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "    init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                               values=mapping)\n",
    "    table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "    input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "    out = tf.one_hot(table.lookup(input_characters), \n",
    "                      depth = 4, \n",
    "                      dtype=tf.float32)\n",
    "    return out\n",
    "\n",
    "def deserialize_val_TSS(serialized_example,input_length,max_shift,output_length_ATAC,\n",
    "                        output_length,crop_size,output_res,predict_masked_atac_bool,atac_mask_dropout, use_global_acc, use_atac, log_atac,g):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cage': tf.io.FixedLenFeature([], tf.string),\n",
    "        'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cell_specific_conv_arr': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    seq_shift = 5\n",
    "    input_seq_length = input_length + max_shift\n",
    "\n",
    "    ### rev_comp\n",
    "    #rev_comp = random.randrange(0,2)\n",
    "\n",
    "    data = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                 seq_shift,input_length))\n",
    "    \n",
    "    \n",
    "    #### parse ATAC and transform as specified\n",
    "    atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length_ATAC,1])\n",
    "    diff = tf.math.sqrt(tf.nn.relu(atac - 64.0 * tf.ones(atac.shape)))\n",
    "    atac = tf.clip_by_value(atac, clip_value_min=0.0, clip_value_max=64.0) + diff\n",
    "    atac = tf.cast(tf.cast(atac,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "    atac_target = atac\n",
    "\n",
    "    if log_atac: \n",
    "        atac = tf.math.log1p(atac)\n",
    "        \n",
    "        \n",
    "    if not use_atac:\n",
    "        atac = tf.math.abs(g.normal(atac.shape,\n",
    "                             mean=0.0,\n",
    "                             stddev=0.00001,\n",
    "                             dtype=tf.float32))\n",
    "                           \n",
    "    ### here we generate a masked output vector length since we are predicting at 1536\n",
    "    atac_mask = tf.ones(output_length // 2,dtype=tf.float32)\n",
    "    atac_mask=tf.nn.experimental.stateless_dropout(atac_mask, \n",
    "                                                     rate=(atac_mask_dropout), \n",
    "                                                     seed=[0,seq_shift]) / (1. / (1.0-(atac_mask_dropout)))\n",
    "    atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "    atac_mask = tf.tile(atac_mask, [1,2])\n",
    "    atac_mask = tf.reshape(atac_mask, [-1])\n",
    "    atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "    if atac_mask_dropout == 0.0:\n",
    "        atac_mask_store = tf.ones_like(atac_mask)\n",
    "    else:\n",
    "        atac_mask_store = 1.0 - atac_mask ## invert the mask, since we want to store which values were masked and loss should be computed over\n",
    "    atac_mask_store = tf.slice(atac_mask_store,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "    tiling_req = output_length_ATAC // output_length\n",
    "    atac_mask = tf.expand_dims(tf.reshape(tf.tile(atac_mask, [1,tiling_req]),[-1]),axis=1)\n",
    "\n",
    "    masked_atac = atac * atac_mask\n",
    "    \n",
    "    cage = tf.ensure_shape(tf.io.parse_tensor(data['cage'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length - 2*crop_size,1])\n",
    "    diff = tf.math.sqrt(tf.nn.relu(cage - 850.0 * tf.ones(cage.shape)))\n",
    "    cage = tf.clip_by_value(cage, clip_value_min=0.0, clip_value_max=850.0) + diff\n",
    "    cage = tf.cast(tf.cast(cage,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "    \n",
    "    tss_tokens = tf.io.parse_tensor(data['tss_tokens'],\n",
    "                                  out_type=tf.int32)\n",
    "    tss_tokens = tf.expand_dims(tss_tokens,axis=1)\n",
    "    \n",
    "    global_acc = tf.ensure_shape(tf.io.parse_tensor(data['cell_specific_conv_arr'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [1536])\n",
    "    global_acc=tf.expand_dims(global_acc,axis=0)\n",
    "    global_acc = tf.math.asinh(global_acc)\n",
    "    global_acc = (global_acc - tf.math.reduce_mean(global_acc)) / tf.math.reduce_std(global_acc)\n",
    "    \n",
    "    if not use_global_acc:\n",
    "        global_acc = g.normal(global_acc.shape,\n",
    "                              mean=0.0,\n",
    "                              stddev=0.00025,\n",
    "                              dtype=tf.float32)\n",
    "\n",
    "    if predict_masked_atac_bool:\n",
    "        atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,tiling_req]),axis=1,keepdims=True)\n",
    "        diff = tf.math.sqrt(tf.nn.relu(atac_out - 64.0 * tf.ones(atac_out.shape)))\n",
    "        atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=64.0) + diff\n",
    "        atac_out = tf.cast(tf.cast(atac_out,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "        atac_out = tf.slice(atac_out,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "        target = tf.concat([atac_out,cage],axis=1)\n",
    "    \n",
    "\n",
    "    print(tss_tokens.shape)\n",
    "    \n",
    "    if predict_masked_atac_bool:\n",
    "        return {'sequence': tf.ensure_shape(sequence,\n",
    "                                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(masked_atac,\n",
    "                                          [output_length_ATAC,1]),\n",
    "                'atac_mask': tf.ensure_shape(atac_mask_store,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'target': tf.ensure_shape(target,\n",
    "                                          [output_length-crop_size*2,2]),\n",
    "                'tss_tokens': tf.ensure_shape(tss_tokens,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'global_acc': tf.ensure_shape(global_acc,\n",
    "                                          [1,1536])}\n",
    "    else:\n",
    "        return {'sequence': tf.ensure_shape(sequence,\n",
    "                                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(atac,\n",
    "                                          [output_length_ATAC,1]),\n",
    "                'target': tf.ensure_shape(cage,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'tss_tokens': tf.ensure_shape(tss_tokens,\n",
    "                                          [output_length-crop_size*2,1]),\n",
    "                'global_acc': tf.ensure_shape(global_acc,\n",
    "                                          [1,1536])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006b94df-2730-4477-b685-c5dd2fca60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Executor.__del__ at 0x7fb68c713cb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
      "    self.wait()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
      "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\n",
      "\t [[{{node EnsureShape_7}}]]\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1678464977.178263258\",\"description\":\"Error received from peer ipv4:10.93.119.234:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\\n\\t [[{{node EnsureShape_7}}]]\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\n\t [[{{node EnsureShape_7}}]]\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1678465122.916985199\",\"description\":\"Error received from peer ipv4:10.93.119.234:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\\n\\t [[{{node EnsureShape_7}}]]\",\"grpc_status\":3}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2450\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\n\t [[{{node EnsureShape_7}}]]\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1678465122.916985199\",\"description\":\"Error received from peer ipv4:10.93.119.234:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\\n\\t [[{{node EnsureShape_7}}]]\",\"grpc_status\":3} [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25065/4014381481.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                       num_parallel_calls=4)\n\u001b[1;32m     20\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2454\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\n\t [[{{node EnsureShape_7}}]]\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1678465122.916985199\",\"description\":\"Error received from peer ipv4:10.93.119.234:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Shape of tensor ExpandDims_3 [512,1] is not compatible with expected shape [312,1].\\n\\t [[{{node EnsureShape_7}}]]\",\"grpc_status\":3}"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(\"gs://picard-testing-176520/test/train/HG_A375.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "g = tf.random.Generator.from_non_deterministic_state()\n",
    "dataset = dataset.map(lambda record: deserialize_val_TSS(record,\n",
    "                                                         65536,\n",
    "                                                         10,\n",
    "                                                         16384,\n",
    "                                                         512,\n",
    "                                                         100,\n",
    "                                                         128,\n",
    "                                                         True,\n",
    "                                                         0.0, \n",
    "                                                         True, \n",
    "                                                         True, \n",
    "                                                         True,\n",
    "                                                         g),\n",
    "                      deterministic=False,\n",
    "                      num_parallel_calls=4)\n",
    "test = iter(dataset)\n",
    "out = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421684c-c02c-4285-9326-7d8ed8ff648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = next(test)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cac45-b709-473d-bb0b-b40efce9fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <tf.Tensor: shape=(65536, 4), dtype=float32, numpy=\n",
       " array([[0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.]], dtype=float32)>,\n",
       " 'atac': <tf.Tensor: shape=(16384, 1), dtype=float32, numpy=\n",
       " array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.6374239 ],\n",
       "        [0.20122541],\n",
       "        [0.5118993 ]], dtype=float32)>,\n",
       " 'atac_mask': <tf.Tensor: shape=(312, 1), dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32)>,\n",
       " 'target': <tf.Tensor: shape=(312, 2), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 9.359375  ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 2.0058594 ,  0.        ],\n",
       "        [ 0.66845703,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 5.3515625 ,  0.        ],\n",
       "        [ 9.359375  ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 1.3369141 ,  0.        ],\n",
       "        [10.6953125 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 3.7890625 ,  0.        ],\n",
       "        [18.9375    ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [16.046875  ,  0.        ],\n",
       "        [19.609375  ,  0.        ],\n",
       "        [ 5.7929688 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 1.3369141 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [37.4375    ,  0.        ],\n",
       "        [71.375     ,  0.        ],\n",
       "        [31.640625  ,  0.        ],\n",
       "        [ 9.8046875 ,  0.        ],\n",
       "        [11.140625  ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [16.046875  ,  0.        ],\n",
       "        [22.0625    ,  0.        ],\n",
       "        [43.90625   ,  0.        ],\n",
       "        [ 6.2421875 ,  0.        ],\n",
       "        [10.4765625 ,  0.        ],\n",
       "        [28.296875  ,  0.        ],\n",
       "        [38.78125   ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 5.3515625 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 6.015625  ,  0.        ],\n",
       "        [12.703125  ,  0.        ],\n",
       "        [11.140625  ,  0.        ],\n",
       "        [12.921875  ,  0.        ],\n",
       "        [14.7109375 ,  0.        ],\n",
       "        [11.140625  ,  0.        ],\n",
       "        [28.96875   ,  0.        ],\n",
       "        [69.9375    ,  0.        ],\n",
       "        [42.78125   ,  0.        ],\n",
       "        [33.4375    ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [18.71875   ,  0.        ],\n",
       "        [ 5.5703125 ,  0.        ],\n",
       "        [ 6.4648438 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [10.6953125 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 6.2382812 ,  0.        ],\n",
       "        [ 4.4570312 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 7.578125  ,  0.        ],\n",
       "        [11.140625  ,  0.        ],\n",
       "        [13.375     ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [ 0.89160156,  0.        ],\n",
       "        [ 7.1328125 ,  0.        ],\n",
       "        [10.6953125 ,  0.        ],\n",
       "        [14.265625  ,  0.        ],\n",
       "        [ 1.7832031 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [16.046875  ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 4.9023438 ,  0.        ],\n",
       "        [ 4.9023438 ,  0.        ],\n",
       "        [10.25      ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 3.7890625 ,  0.        ],\n",
       "        [11.8125    ,  0.        ],\n",
       "        [ 7.1328125 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 4.6796875 ,  0.        ],\n",
       "        [ 3.3417969 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [11.8125    ,  0.        ],\n",
       "        [36.09375   ,  0.        ],\n",
       "        [25.625     ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [16.046875  ,  0.        ],\n",
       "        [16.9375    ,  0.        ],\n",
       "        [12.4765625 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 5.3515625 ,  0.        ],\n",
       "        [28.53125   ,  0.        ],\n",
       "        [ 6.2421875 ,  0.        ],\n",
       "        [74.625     ,  0.        ],\n",
       "        [87.4375    ,  0.        ],\n",
       "        [74.3125    ,  0.        ],\n",
       "        [12.2578125 ,  0.        ],\n",
       "        [10.6953125 ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 9.359375  ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.7915039 ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  1.5830078 ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [14.7109375 ,  0.        ],\n",
       "        [14.7109375 ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 1.7832031 ,  0.        ],\n",
       "        [11.5859375 ,  0.        ],\n",
       "        [77.1875    ,  0.        ],\n",
       "        [68.        ,  0.        ],\n",
       "        [ 6.015625  ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [14.7109375 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3369141 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3369141 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [35.        ,  0.        ],\n",
       "        [17.15625   ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 5.125     ,  0.        ],\n",
       "        [ 8.25      ,  0.        ],\n",
       "        [ 9.359375  ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 1.5595703 ,  0.        ],\n",
       "        [ 3.7890625 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 5.796875  ,  0.        ],\n",
       "        [ 6.2421875 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [79.0625    ,  0.        ],\n",
       "        [79.125     ,  0.        ],\n",
       "        [34.53125   ,  0.        ],\n",
       "        [11.8125    ,  0.        ],\n",
       "        [16.265625  ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.3369141 ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 2.6757812 ,  0.        ],\n",
       "        [ 6.2421875 ,  0.        ],\n",
       "        [ 5.796875  ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 9.359375  ,  0.        ],\n",
       "        [12.03125   ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [ 8.0234375 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 9.359375  ,  0.        ],\n",
       "        [56.15625   ,  0.        ],\n",
       "        [49.46875   ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [10.03125   ,  0.        ],\n",
       "        [18.046875  ,  0.        ],\n",
       "        [12.0390625 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [57.5       ,  0.        ],\n",
       "        [29.640625  ,  0.        ],\n",
       "        [ 2.4511719 ,  0.        ],\n",
       "        [ 2.6738281 ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 4.234375  ,  0.        ],\n",
       "        [ 7.1328125 ,  0.        ],\n",
       "        [ 9.1328125 ,  0.        ],\n",
       "        [69.5625    ,  0.        ],\n",
       "        [30.078125  ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 1.5605469 ,  0.        ],\n",
       "        [ 3.34375   ,  0.        ],\n",
       "        [ 8.6953125 ,  0.        ],\n",
       "        [11.8125    ,  0.        ],\n",
       "        [33.4375    ,  0.        ],\n",
       "        [ 4.0117188 ,  0.        ],\n",
       "        [ 1.3378906 ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [27.40625   ,  0.        ],\n",
       "        [12.703125  ,  0.        ],\n",
       "        [27.625     ,  0.        ],\n",
       "        [19.171875  ,  0.        ],\n",
       "        [ 6.6875    ,  0.        ],\n",
       "        [67.        ,  0.        ],\n",
       "        [69.875     ,  0.        ],\n",
       "        [ 5.3476562 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 1.7832031 ,  0.        ],\n",
       "        [ 0.89160156,  0.        ],\n",
       "        [26.75      ,  0.        ]], dtype=float32)>,\n",
       " 'global_acc': <tf.Tensor: shape=(1, 1536), dtype=float32, numpy=\n",
       " array([[-0.5336828, -0.6923188,  1.8194746, ..., -0.8249886, -1.0448451,\n",
       "          1.4671166]], dtype=float32)>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "counter = 0\n",
    "for k in range(10000):\n",
    "    out = g.uniform([], 0, 3,dtype=tf.int32)\n",
    "    if out == 0:\n",
    "        counter += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4981f-353e-4a24-bccc-7934bd7dd409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
