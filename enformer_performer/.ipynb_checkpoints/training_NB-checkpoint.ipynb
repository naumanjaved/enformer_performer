{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f91784-f159-4d80-a394-1c57ea7d900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 20:08:10.545163: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 20:08:10.913393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-22 20:08:10.913442: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-22 20:08:11.979542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 20:08:11.979743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 20:08:11.979760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "#os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import metrics as metrics\n",
    "from optimizers import *\n",
    "import schedulers as schedulers\n",
    "\n",
    "import training_utils as training_utils\n",
    "\n",
    "import enformer_performer as enformer_performer\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33684ed-393f-4af6-83b8-ed8150d9be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:53:43.584486: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:53:43.584540: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-14 14:53:43.584569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:53:43.916129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 14:53:43.942912: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://localhost:33697\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-5')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy=\\\n",
    "        tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    options.experimental_threading.max_intra_op_parallelism=1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1 # batch size 24, use LR ~ 2.5 e -04\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93effd89-8681-48e6-be68-36e027605040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393216\n",
      "896\n",
      "0\n",
      "2696\n"
     ]
    }
   ],
   "source": [
    "iterators={'human': ('gs://genformer_data/expanded_originals/no_TF/393k',2696),\n",
    "           'mouse': ('gs://genformer_data/expanded_originals/no_TF/393k',987),\n",
    "           'canine': ('gs://genformer_data/expanded_originals/no_TF/393k',13),\n",
    "           'rhesus': ('gs://genformer_data/expanded_originals/no_TF/393k',15),\n",
    "           'rat': ('gs://genformer_data/expanded_originals/no_TF/393k',13)}\n",
    "           \n",
    "g = tf.random.Generator.from_non_deterministic_state()\n",
    "tr_data_it_dict,val_data_it_dict,val_data_TSS_it =  \\\n",
    "    training_utils.return_distributed_iterators(iterators,\n",
    "                                                \"gs://genformer_data/expanded_originals/no_TF/393k/human/tfrecords_tss\",\n",
    "                                                2696,\n",
    "                                                 GLOBAL_BATCH_SIZE,\n",
    "                                                 393216,\n",
    "                                                 3072,\n",
    "                                                 1088,\n",
    "                                                 10,\n",
    "                                                 4,\n",
    "                                                 10,\n",
    "                                                 strategy,\n",
    "                                                 options,\n",
    "                                                 g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0de2869-14d8-46c8-9efd-77cb51e28a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = enformer_performer.enformer_performer(\n",
    "        num_transformer_layers=6,\n",
    "        num_heads=8,\n",
    "        heads_channels= {'human': 2696,\n",
    "                         'mouse': 987,\n",
    "                         'canine': 13,\n",
    "                         'rhesus': 15,\n",
    "                         'rat': 13},\n",
    "        out_length=3072,\n",
    "        target_length=896,\n",
    "        stable_variant=True,\n",
    "        dim=192,\n",
    "        d_model=1536,\n",
    "        norm=True,\n",
    "        max_seq_length=3072,\n",
    "        nb_random_features=256,\n",
    "        hidden_size=1536,\n",
    "        numerical_stabilizer=0.001,\n",
    "        rel_pos_bins=3072,\n",
    "        use_mask_pos=False,\n",
    "        use_rot_emb=True,\n",
    "        kernel_transformation=\"softmax_kernel_transformation\",\n",
    "        normalize=True,\n",
    "        seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb20d1ad-4e38-4e69-9e29-75a19e7bfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():        \n",
    "\n",
    "    optimizer1 = tf.keras.optimizers.Adam(learning_rate=1.0e-04)\n",
    "\n",
    "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=1.0e-04)\n",
    "    optimizers_in = optimizer1,optimizer2\n",
    "\n",
    "    metric_dict = {}\n",
    "    organism_dict = {'human': 50,\n",
    "                     'mouse': 50,\n",
    "                     'rhesus':30,\n",
    "                     'rat': 30,\n",
    "                     'canine': 30}\n",
    "\n",
    "                               \n",
    "    dist_train_step, dist_val_step_h,dist_val_step_m, val_step_TSS, build_step,metric_dict = training_utils.return_train_val_functions(model,\n",
    "                                                                                                                                       50,\n",
    "                                                                                                                                       organism_dict,\n",
    "                                                                                                                                         50,\n",
    "                                                                                                                                       optimizers_in,\n",
    "                                                                                                                                        2058,\n",
    "                                                                                                                                         strategy,\n",
    "                                                                                                                                         metric_dict, \n",
    "                                                                                                                                         GLOBAL_BATCH_SIZE,\n",
    "                                                                                                                                        5.0,\n",
    "                                                                                                                                         BATCH_SIZE_PER_REPLICA,\n",
    "                                                                                                                                        loss_fn_main='poisson')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400a655-9fec-4661-aa56-415bf14c3191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch_ 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_14/kernel:0', 'enformer_performer/dense_14/bias:0', 'enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TPUExtended._tpu_function_creator.<locals>.tpu_function at 0x7f5756375c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TPUExtended._tpu_function_creator.<locals>.tpu_function at 0x7f5756375c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['enformer_performer/dense_12/kernel:0', 'enformer_performer/dense_12/bias:0', 'enformer_performer/dense_13/kernel:0', 'enformer_performer/dense_13/bias:0', 'enformer_performer/dense_16/kernel:0', 'enformer_performer/dense_16/bias:0', 'enformer_performer/dense_15/kernel:0', 'enformer_performer/dense_15/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():        \n",
    "    ### main training loop\n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, 4):\n",
    "        print('starting epoch_', str(epoch_i))\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            # run once to build the model w/o updating anything\n",
    "            build_step(val_data_it_dict['human'])\n",
    "\n",
    "        assert len(organism_dict.keys()) == len(tr_data_it_dict.keys())\n",
    "            \n",
    "        iters = (tr_data_it_dict['human'],\n",
    "                        tr_data_it_dict['mouse'],\n",
    "                        tr_data_it_dict['rhesus'],\n",
    "                        tr_data_it_dict['rat'],\n",
    "                        tr_data_it_dict['canine'])\n",
    "        dist_train_step(iters)\n",
    "        \n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('hg_train_loss: ' + str(metric_dict['human_tr'].result().numpy()))\n",
    "        \n",
    "        print('training duration(mins): ' + str(duration))\n",
    "\n",
    "        start = time.time()\n",
    "        dist_val_step_h(val_data_it_dict['human'])\n",
    "\n",
    "        print('val_loss: ' + str(metric_dict['human_val'].result().numpy()))\n",
    "        val_losses.append(metric_dict['human_val'].result().numpy())\n",
    "\n",
    "        print('human_pearsonsR: ')\n",
    "        pearsonsR=metric_dict['human_pearsonsR'].result()['PearsonR'].numpy()\n",
    "        print(pearsonsR)\n",
    "\n",
    "        val_pearsons.append(np.nanmedian(pearsonsR))\n",
    "        print('human_R2: ')\n",
    "        print(metric_dict['human_R2'].result()['R2'].numpy())\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i) + ' validation')\n",
    "        print('validation duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "\n",
    "        \n",
    "        val_step_TSS(val_data_TSS_it)\n",
    "        \n",
    "\n",
    "        y_trues = metric_dict['hg_corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['hg_corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['hg_corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['hg_corr_stats'].result()['gene_map'].numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (epoch_i > 2):\n",
    "            stop_criteria,patience_counter,best_epoch = \\\n",
    "                training_utils.early_stopping(current_val_loss=val_losses[-1],\n",
    "                                                logged_val_losses=val_losses,\n",
    "                                                current_pearsons=val_pearsons[-1],\n",
    "                                                logged_pearsons=val_pearsons,\n",
    "                                                current_epoch=epoch_i,\n",
    "                                                best_epoch=best_epoch,\n",
    "                                                save_freq=5,\n",
    "                                                patience=5,\n",
    "                                                patience_counter=patience_counter,\n",
    "                                                min_delta=1.0e-05,\n",
    "                                                model=enformer_model,\n",
    "                                                save_directory=\"gs://picard-testing-176520/test\",\n",
    "                                                saved_model_basename=\"test_model\",\n",
    "                                                checkpoint=checkpoint)\n",
    "        #plt.close('all')\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7115bb-73bd-4146-af2d-1b2ebbdda3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deserialize_val_TSS(serialized_example,\n",
    "                        input_length, output_length,crop_size,\n",
    "                        max_shift,num_targets):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.string),\n",
    "        'tss_mask': tf.io.FixedLenFeature([], tf.string),\n",
    "        'gene_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bin_unique': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    shift = 5\n",
    "    input_seq_length = input_length + max_shift\n",
    "    interval_end = input_length + shift\n",
    "    \n",
    "\n",
    "    example = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "    sequence = tf.reshape(sequence, (input_length + max_shift, 4))\n",
    "    sequence = tf.cast(sequence, tf.float32)\n",
    "    sequence = tf.slice(sequence, [shift,0],[input_length,-1])\n",
    "    \n",
    "    target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "    target = tf.reshape(target,\n",
    "                        (output_length, num_targets))\n",
    "    #print(target.shape)\n",
    "    target = tf.slice(target,[crop_size,0],\n",
    "                             [output_length - 2*crop_size,-1])\n",
    "\n",
    "    bin_unique = tf.io.parse_tensor(example['bin_unique'],\n",
    "                                  out_type=tf.int32)\n",
    "    \n",
    "    tss_mask = tf.io.parse_tensor(example['tss_mask'],\n",
    "                                  out_type=tf.int32)\n",
    "    tss_mask = tf.slice(tss_mask,[crop_size,0],\n",
    "                             [output_length - 2*crop_size,-1])\n",
    "\n",
    "    gene_name= tf.io.parse_tensor(example['gene_name'],out_type=tf.int32)\n",
    "    gene_name = tf.tile(tf.expand_dims(gene_name,axis=0),[638])\n",
    "    cell_types = tf.range(0,638)\n",
    "    \n",
    "\n",
    "    return {'sequence': tf.ensure_shape(sequence,\n",
    "                                        [input_length,4]),\n",
    "            'target': tf.ensure_shape(target,\n",
    "                                      [output_length - 2*crop_size,num_targets]),\n",
    "            'tss_mask': tf.ensure_shape(tss_mask,\n",
    "                                        [output_length - 2*crop_size,1]),\n",
    "            'gene_name': tf.ensure_shape(gene_name,\n",
    "                                         [638,]),\n",
    "            'bin_unique': tf.ensure_shape(bin_unique,\n",
    "                                         [1,]),\n",
    "            'cell_types': tf.ensure_shape(cell_types,\n",
    "                                           [638,])}\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(\"gs://genformer_data/expanded_originals_tss_mask/196k/human/tfrecords_tss/tssmask-train-0-0.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "#dataset = dataset.with_options(options)\n",
    "\n",
    "dataset = dataset.map(lambda record: deserialize_val_TSS(record,\n",
    "                                                         196608, \n",
    "                                                        1536,\n",
    "                                                        320,\n",
    "                                                         10,\n",
    "                                                         5313),\n",
    "                      deterministic=False,\n",
    "                      num_parallel_calls=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f708c9b8-3302-45e0-8c1d-64e1dc3abdaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_6_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected size[0] in [0, 576], but got 896\n\t [[{{node Slice_2}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12375/1276527709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_6_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected size[0] in [0, 576], but got 896\n\t [[{{node Slice_2}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "test_iter = iter(dataset)\n",
    "test = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f01928-3667-4096-a422-57cb5c0bfd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
